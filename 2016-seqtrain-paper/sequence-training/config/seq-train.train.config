# Include corpus, lexicon, HMM like in train setup. Also LM.
include seq-train.scales.config
include lexicon.config
include common.config
include corpus.config
include hmm.config

include mfcc.lda.sat.config


[*]
log-file 		   = log/seq-train.train.log
job-name                   = seq-train
use-cuda		   = false # This is for Sprint only.
seed			   = 1  # Default.
allophone-file		   = deps/allophones

[*]
#frame-rejection-threshold = 0.000001			# TODO(MMI) uncomment for MMI
alignment-label-type       = emission-ids		# !! same setting
ce-smoothing-weight	   = 0   # CRNN will do it
lm.warning.channel	   = nil


# Neural network, PythonLayer (which returns log-probs) + BiasLayer (where the log-prior will be removed from by Sprint)
[*.neural-network]
links                       = 0->python-layer:0

[*.python-layer]
layer-type                  = python
links                       = 0->bias-layer:0
dimension-input             = 45	# input is ignored, normalization done in extern sprint dataset
dimension-output            = $(number-of-classes)

[*.bias-layer]
layer-type                  = bias
dimension-input             = $(number-of-classes)
dimension-output            = $(number-of-classes)


# PythonSegmentOrder
[*]
python-segment-order		= true
python-segment-order-pymod-path = .
python-segment-order-pymod-name = returnn.SprintControl
use-data-source			= false

# Python trainer config
[*]
python-control-enabled		= true
pymod-path			= .
pymod-name			= returnn.SprintControl


[*]
weighted-accumulation	= false
prior-file		= deps/prior.xml

priori-scale            = 1.0 # was 0.6, but wsj trained with 0.4

# TODO set this value, typically 1/lm-scale, but could be tuned
arc-scale		= $(scores-scaling-factor)

[*]
#unbuffered 		= true	# for debugging only
#corpus.partition	= 100   # for debugging only
measure-time		= true
log-step-size		= true

# ---------------------------------------------------------------------------
[*]
log-channel.file        = $(log-file)
no-dependency-check     = true
progress-indication	= global


# -----------------------------------------------------------------
[lattice-processor]
actions                 = read,rescore,linear-combination,accumulate-discriminatively#,single-best,evaluate
selections              = topology-reader,rescoring,linear-combination,accumulation#,foo,bar


[*.topology-reader]
readers                             = tdps,accuracy
#readers                            = tdps			# TODO(MMI) uncomment for MMI
lattice-archive.path                = $(denominator-cache-path)
lattice-archive.lm-scale            = 0.0
lattice-archive.pronunciation-scale = 0.0

[*.rescoring]
nn-emission-rescorers       = nn-em-rescorer
combined-lm-rescorers       = lm-rescorer
pass-extractors             = tdps,accuracy
*.fall-back-value           = 10000
#pass-extractors             = tdps				# TODO(MMI) uncomment for MMI

[*.linear-combination]
outputs                     = total accuracy
#outputs                     = total				# TODO(MMI) uncomment for MMI
accuracy.scales             = 0.00 0.00 0.00 1.00
#TODO adapt forth value for incorporating margin
total.scales                = $(arc-scale) $(arc-scale) $(arc-scale) 0.0
#total.scales                = $(arc-scale) $(arc-scale) $(arc-scale) 	# TODO(MMI) uncomment for MMI


[*.accumulation]
model-type                  = neural-network
criterion                   = ME # ME for MPE and sMBR, MMI for Maximum Mutual Information
posterior-tolerance         = 100
lattice-name                = total

# setup of estimator. this would mostly be ignored
[*]
estimator		= dry-run
batch-mode		= false


# ---------------------------------------------------------------------------
# acoustic model
[*.state-tying]
type                = cart
file                = $(recog-cart-file)
dump-state-tying.channel    = nil

# nn-em-rescorer does not require a feature scorer, just use a dummy here
[*.acoustic-model.mixture-set]
feature-scorer-type     = diagonal-maximum


# ---------------------------------------------------------------------------
[*]
port-name               = features

# do not realign arcs in this setup (currently not possible to do this efficiently)
[*.segmentwise-alignment.alignment-cache]
path                    = $(alignment-cache-path)
read-only               = true

# these values are not used, because we dont realign
[*.aligner]
min-acoustic-pruning            = 400
max-acoustic-pruning            = 3200
min-average-number-of-states        = 12
increase-pruning-until-no-score-difference = true
statistics.channel          = log-channel
